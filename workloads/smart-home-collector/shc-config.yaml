apiVersion: v1

kind: ConfigMap
metadata:
  name: smart-home-collector-config
  namespace: triggers
data:
  telegraf.conf: |+
    # Telegraf Configuration
    #
    # Telegraf is entirely plugin driven. All metrics are gathered from the
    # declared inputs, and sent to the declared outputs.
    #
    # Plugins must be declared in here to be active.
    # To deactivate a plugin, comment out the name and any variables.
    #
    # Use 'telegraf -config telegraf.conf -test' to see what metrics a config
    # file would generate.
    #
    # Environment variables can be used anywhere in this config file, simply prepend
    # them with $. For strings the variable must be within quotes (ie, "$STR_VAR"),
    # for numbers and booleans they should be plain (ie, $INT_VAR, $BOOL_VAR)


    # Global tags can be specified here in key="value" format.
    [global_tags]

    # Configuration for telegraf agent
    [agent]
      ## Default data collection interval for all inputs
      interval = "1m"
      ## Rounds collection interval to 'interval'
      ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
      round_interval = true

      ## Telegraf will send metrics to outputs in batches of at most
      ## metric_batch_size metrics.
      ## This controls the size of writes that Telegraf sends to output plugins.
      metric_batch_size = 1000

      ## For failed writes, telegraf will cache metric_buffer_limit metrics for each
      ## output, and will flush this buffer on a successful write. Oldest metrics
      ## are dropped first when this buffer fills.
      ## This buffer only fills when writes fail to output plugin(s).
      metric_buffer_limit = 10000

      ## Collection jitter is used to jitter the collection by a random amount.
      ## Each plugin will sleep for a random time within jitter before collecting.
      ## This can be used to avoid many plugins querying things like sysfs at the
      ## same time, which can have a measurable effect on the system.
      collection_jitter = "0s"

      ## Default flushing interval for all outputs. Maximum flush_interval will be
      ## flush_interval + flush_jitter
      flush_interval = "10s"
      ## Jitter the flush interval by a random amount. This is primarily to avoid
      ## large write spikes for users running a large number of telegraf instances.
      ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
      flush_jitter = "0s"

      ## By default or when set to "0s", precision will be set to the same
      ## timestamp order as the collection interval, with the maximum being 1s.
      ##   ie, when interval = "10s", precision will be "1s"
      ##       when interval = "250ms", precision will be "1ms"
      ## Precision will NOT be used for service inputs. It is up to each individual
      ## service input to set the timestamp at the appropriate precision.
      ## Valid time units are "ns", "us" (or "Âµs"), "ms", "s".
      precision = ""

      ## Logging configuration:
      ## Run telegraf with debug log messages.
      debug = false
      ## Run telegraf in quiet mode (error log messages only).
      quiet = false
      ## Specify the log file name. The empty string means to log to stderr.
      logfile = ""

      ## Override default hostname, if empty use os.Hostname()
      #hostname = "$NODE_NAME"
      ## If set to true, do no set the "host" tag in the telegraf agent.
      omit_hostname = true




    ###############################################################################
    #                            OUTPUT PLUGINS                                   #
    ###############################################################################

    # Configuration for sending metrics to InfluxDB
    [[outputs.influxdb]]
      ## The full HTTP or UDP URL for your InfluxDB instance.
      ##
      ## Multiple URLs can be specified for a single cluster, only ONE of the
      ## urls will be written to each interval.
      # urls = ["unix:///var/run/influxdb.sock"]
      # urls = ["udp://127.0.0.1:8089"]
      # urls = ["http://127.0.0.1:8086"]
      urls = ["$INFLUXDB_URL"]

      ## The target database for metrics; will be created as needed.
      database = "$INFLUXDB_DB"

      ## If true, no CREATE DATABASE queries will be sent.  Set to true when using
      ## Telegraf with a user without permissions to create databases or when the
      ## database already exists.
      # skip_database_creation = false

      ## Name of existing retention policy to write to.  Empty string writes to
      ## the default retention policy.  Only takes effect when using HTTP.
      # retention_policy = ""

      ## Write consistency (clusters only), can be: "any", "one", "quorum", "all".
      ## Only takes effect when using HTTP.
      # write_consistency = "any"

      ## Timeout for HTTP messages.
      # timeout = "5s"

      ## HTTP Basic Auth
      username = "$INFLUXDB_USER"
      password = "$INFLUXDB_USER_PASSWORD"

      ## HTTP User-Agent
      # user_agent = "telegraf"

      ## UDP payload size is the maximum packet size to send.
      # udp_payload = 512

      ## Optional TLS Config for use on HTTP connections.
      # tls_ca = "/etc/telegraf/ca.pem"
      # tls_cert = "/etc/telegraf/cert.pem"
      # tls_key = "/etc/telegraf/key.pem"
      ## Use TLS but skip chain & host verification
      # insecure_skip_verify = false

      ## HTTP Proxy override, if unset values the standard proxy environment
      ## variables are consulted to determine which proxy, if any, should be used.
      # http_proxy = "http://corporate.proxy:3128"

      ## Additional HTTP headers
      # http_headers = {"X-Special-Header" = "Special-Value"}

      ## HTTP Content-Encoding for write request body, can be set to "gzip" to
      ## compress body or "identity" to apply no encoding.
      # content_encoding = "identity"

      ## When true, Telegraf will output unsigned integers as unsigned values,
      ## i.e.: "42u".  You will need a version of InfluxDB supporting unsigned
      ## integer values.  Enabling this option will result in field type errors if
      ## existing data has been written.
      # influx_uint_support = false

      #[[outputs.file]]
      ## Files to write to, "stdout" is a specially handled file.
      #files = ["stdout", "/tmp/metrics.out"]

      ## Use batch serialization format instead of line based delimiting.  The
      ## batch format allows for the production of non line based output formats and
      ## may more effiently encode and write metrics.
      # use_batch_format = false

      ## The file will be rotated after the time interval specified.  When set
      ## to 0 no time based rotation is performed.
      # rotation_interval = "0h"

      ## The logfile will be rotated when it becomes larger than the specified
      ## size.  When set to 0 no size based rotation is performed.
      #rotation_max_size = "10MB"

      ## Maximum number of rotated archives to keep, any older logs are deleted.
      ## If set to -1, no archives are removed.
      #rotation_max_archives = 5

      ## Data format to output.
      ## Each data format has its own unique set of configuration options, read
      ## more about them here:
      ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md
      #data_format = "influx"

    ###############################################################################
    #                            INPUT PLUGINS                                    #
    ###############################################################################

    # Read metrics from MQTT topic(s)
    [[inputs.mqtt_consumer]]
      ## MQTT broker URLs to be used. The format should be scheme://host:port,
      ## schema can be tcp, ssl, or ws.
      servers = ["tcp://192.168.1.202:1883"]
    
      ## Topics that will be subscribed to.
      topics = [
        "telegraf/#",
        "sensor/#"
      ]
    
      ## The message topic will be stored in a tag specified by this value.  If set
      ## to the empty string no topic tag will be created.
      topic_tag = ""
    
      ## QoS policy for messages
      ##   0 = at most once
      ##   1 = at least once
      ##   2 = exactly once
      ##
      ## When using a QoS of 1 or 2, you should enable persistent_session to allow
      ## resuming unacknowledged messages.
      # qos = 0
    
      ## Connection timeout for initial connection in seconds
      # connection_timeout = "30s"
    
      ## Maximum messages to read from the broker that have not been written by an
      ## output.  For best throughput set based on the number of metrics within
      ## each message and the size of the output's metric_batch_size.
      ##
      ## For example, if each message from the queue contains 10 metrics and the
      ## output metric_batch_size is 1000, setting this to 100 will ensure that a
      ## full batch is collected and the write is triggered immediately without
      ## waiting until the next flush_interval.
      # max_undelivered_messages = 1000
    
      ## Persistent session disables clearing of the client session on connection.
      ## In order for this option to work you must also set client_id to identify
      ## the client.  To receive messages that arrived while the client is offline,
      ## also set the qos option to 1 or 2 and don't forget to also set the QoS when
      ## publishing.
      # persistent_session = false
    
      ## If unset, a random client ID will be generated.
      # client_id = ""
    
      #   ## Username and password to connect MQTT server.
      # username = "telegraf"
      # password = "metricsmetricsmetricsmetrics"
    
      ## Optional TLS Config
      # tls_ca = "/etc/telegraf/ca.pem"
      # tls_cert = "/etc/telegraf/cert.pem"
      # tls_key = "/etc/telegraf/key.pem"
      ## Use TLS but skip chain & host verification
      # insecure_skip_verify = false
    
      ## Data format to consume.
      ## Each data format has its own unique set of configuration options, read
      ## more about them here:
      ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md
      data_format = "influx"

    [[inputs.kube_inventory]]
      ## URL for the Kubernetes API
      url = "https://kubernetes.default.svc"

      ## Namespace to use. Set to "" to use all namespaces.
      namespace = ""

      ## Use bearer token for authorization. ('bearer_token' takes priority)
      ## If both of these are empty, we'll use the default serviceaccount:
      ## at: /run/secrets/kubernetes.io/serviceaccount/token
      bearer_token = "/var/run/secrets/kubernetes.io/serviceaccount/token"
      ## OR
      #bearer_token_string = ""

      ## Set response_timeout (default 5 seconds)
      # response_timeout = "5s"

      ## Optional Resources to exclude from gathering
      ## Leave them with blank with try to gather everything available.
      ## Values can be - "daemonsets", deployments", "endpoints", "ingress", "nodes",
      ## "persistentvolumes", "persistentvolumeclaims", "pods", "services", "statefulsets"
      #resource_exclude = [ "deployments", "nodes", "statefulsets" ]

      ## Optional Resources to include when gathering
      ## Overrides resource_exclude if both set.
      # resource_include = [ "deployments", "nodes", "statefulsets" ]

      ## Optional TLS Config
      # tls_ca = "/path/to/cafile"
      # tls_cert = "/path/to/certfile"
      # tls_key = "/path/to/keyfile"
      ## Use TLS but skip chain & host verification
      insecure_skip_verify = true
      interval = "1m"

    ## Network ##

    #[[inputs.exec]]
    #  commands = ["sh /speedtest.sh"]
    #  timeout = "1m"
    #  data_format = "influx"
    #  interval = "60m"

    [[inputs.ping]]

      # WAN endpoints:
    
      urls = ["www.google.com"] 

    [[inputs.ping]]

      # Network Devices:
      #
      # Network Infrastructure
      # ======================
      # Main Router (VM)    - 192.168.1.1
      # NAS                 - 192.168.1.2
      # Managed Switch      - 192.168.1.3
      # Xiamoi Router 4     - 192.168.1.254
      #
      # Entertainment
      # =============
      # Shield TV           - 192.168.1.10
      # Satelite TV Box     - 192.168.1.11
      # Lounge TV (LAN)     - 192.168.1.12
      # Harry's TV (LAN)    - 192.168.1.13
      # Harry's TV (WiFi)   - 192.168.1.14
      # Chloe's TV (WiFi)   - 
      # Harry's Nintendo    - 
      # Chloe's Nintendo    - 
      # PS5                 - 192.168.1.18
      #
      # Laptops/Phones/Tablets
      # =========
      # Laptop P50          - 192.168.1.21
      # Laptop P50 (VPN)    - 192.168.1.22
      # Carolyn iPhone      - 192.168.1.23
      # Carolyn iPad        - 192.168.1.24
      # Samsung S21         - 192.168.1.25
      # MacBook Pro         - 192.168.1.26
      # Kid's iPad          -
      # Garret SmartWatch   -
      # Carolyn AppleWatch  - 192.168.1.28
      # Harry's Phone       - 192.168.1.29
      #
      # Servers/VMs
      # ===========
      # RPi3 k8s-master     - 192.168.1.30
      # RPi4 k8s-worker1    - 192.168.1.31
      # RPi4 k8s-worker2    - 192.168.1.32
      # RPi4 k8s-worker3    - 192.168.1.33 
      # Lenovo G50-30       - 192.168.1.27 -> 60
      # Lenovo B50-30       - 192.168.1.61
      # Lenovo W541/Proxmox - 192.168.1.62 
      # Lenovo P50/Proxmox  - 192.168.1.63 
      # Lenovo P50/Windows  - 192.168.1.64 
      # 
      # RHEL VPN            - 192.168.1.70
      #
      # Smart Devices
      # =============
      # Chloe light         - 192.168.1.40
      # Harry light         - 192.168.1.41
      # RPi Power Supply    - 192.168.1.42
      # Kasa Energy Socket  - 192.168.1.43
      # LG Tumble Dryer     - 192.168.1.44
      # Bosch Oven          - 192.168.1.45
      # Alexa (Lounge)      - 192.168.1.46
      # Alexa (Bedroom)     - 192.168.1.47
      # Alexa (Harry)       - 192.168.1.48
      # Alexa (Chloe)       - 192.168.1.49
      # Arlo BaseStation    - 192.168.1.50
      # HiveHub             - 192.168.1.51
      # LightwaveRF Hub     - 192.168.1.52
      # Harmony Hub         - 192.168.1.53
      # Google Nest Hub     - 192.168.1.54
      # Zigbee Bridge       - 192.168.1.55


      urls = [
        "192.168.1.1", 
        "192.168.1.2", 
        "192.168.1.3", 
        "192.168.1.10", 
        "192.168.1.11", 
        "192.168.1.12", 
        "192.168.1.13", 
        "192.168.1.14", 
        "192.168.1.18", 
        "192.168.1.23", 
        "192.168.1.24",
        "192.168.1.26",
        "192.168.1.27",  
        "192.168.1.28", 
        "192.168.1.30", 
        "192.168.1.31", 
        "192.168.1.32", 
        "192.168.1.33", 
        "192.168.1.40", 
        "192.168.1.41", 
        "192.168.1.42", 
        "192.168.1.43", 
        "192.168.1.45", 
        "192.168.1.46", 
        "192.168.1.50", 
        "192.168.1.51", 
        "192.168.1.52", 
        "192.168.1.53", 
        "192.168.1.54", 
        "192.168.1.55",
        "192.168.1.64", 
        "192.168.1.70", 
        "192.168.1.254"] 

      [[processors.enum]]

        [[processors.enum.mapping]]
          ## Name of the field to map
          #field = "status"

          ## Name of the tag to map
          tag = "url"

          ## Destination tag or field to be used for the mapped value.  By default the
          ## source tag or field is used, overwriting the original value.
          dest = "host_map"

          ## Default value to be used for all values not contained in the mapping
          ## table.  When unset and no match is found, the original field will remain 
          ## unmodified and the destination tag or field will not be created.
          default = "unknown"

          ## Table of mappings
          [processors.enum.mapping.value_mappings]
            "192.168.1.1" = "Main Router"
            "192.168.1.2" = "Linkstation NAS"
            "192.168.1.3" = "Managed Switch"
            "192.168.1.254" = "WiFi Router - Study"
            "192.168.1.10" = "Shield TV"
            "192.168.1.11" = "zGemma Sat Box"
            "192.168.1.12" = "Lounge TV (LAN)"
            "192.168.1.13" = "Harry's TV (LAN)"
            "192.168.1.14" = "Harry's TV (WiFi)"
            "192.168.1.16" = "Nintendo Switch (Harry)"
            "192.168.1.17" = "Nintendo Switch (Chloe)"
            "192.168.1.18" = "Playstation 5"
            "192.168.1.21" = "Chris's Laptop"
            "192.168.1.22" = "Chris's Laptop (Bonded)"
            "192.168.1.23" = "Carolyn's iPhone"
            "192.168.1.24" = "Carolyn's iPad"
            "192.168.1.25" = "Chris's phone"
            "192.168.1.26" = "MacBook Pro"
            "192.168.1.27" = "Lenovo-G50-30"
            "192.168.1.28" = "Apple Watch"         
            "192.168.1.30" = "Master node"
            "192.168.1.31" = "Worker Node, k8s-worker1"
            "192.168.1.32" = "Worker Node, k8s-worker2"
            "192.168.1.33" = "Worker Node, k8s-worker3"             
            "192.168.1.40" = "Chloe's Light"
            "192.168.1.41" = "Harry's Light"                                         
            "192.168.1.42" = "RPi PSU"
            "192.168.1.43" = "Smart Socket"
            "192.168.1.45" = "Bosch Oven"
            "192.168.1.46" = "Amazon Alexa (Lounge)"
            "192.168.1.47" = "Amazon Alexa (Bedroom)"
            "192.168.1.48" = "Amazon Alexa (Harry)"
            "192.168.1.49" = "Amazon Alexa (Chloe)"
            "192.168.1.50" = "Arlo Basestation"
            "192.168.1.51" = "Hive Hub"
            "192.168.1.52" = "LightwaveRF Hub" 
            "192.168.1.53" = "Harmony Hub"
            "192.168.1.54" = "Google Nest Hub Max"
            "192.168.1.55" = "Zigbee Bridge"
            "192.168.1.60" = "Lenovo G50-30"
            "192.168.1.61" = "Lenovo B50-30"
            "192.168.1.62" = "Proxmox Server"
            "192.168.1.63" = "Proxmox Server II"
            "192.168.1.64" = "Windows Server"
            "192.168.1.70" = "RHEL VPN"
            "www.google.com" = "www.google.com"

    [[inputs.dns_query]]
      servers = ["8.8.8.8"]
      domains = ["www.google.com"]
      record_type = "A"

    [[inputs.net_response]]
      protocol = "tcp"
      address = "www.google.com:80"
      timeout = "1s"
      read_timeout = "1s"
