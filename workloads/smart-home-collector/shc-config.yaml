apiVersion: v1
data:
  telegraf.conf: "# Telegraf Configuration\n#\n# Telegraf is entirely plugin driven.
    All metrics are gathered from the\n# declared inputs, and sent to the declared
    outputs.\n#\n# Plugins must be declared in here to be active.\n# To deactivate
    a plugin, comment out the name and any variables.\n#\n# Use 'telegraf -config
    telegraf.conf -test' to see what metrics a config\n# file would generate.\n#\n#
    Environment variables can be used anywhere in this config file, simply prepend\n#
    them with $. For strings the variable must be within quotes (ie, \"$STR_VAR\"),\n#
    for numbers and booleans they should be plain (ie, $INT_VAR, $BOOL_VAR)\n\n\n#
    Global tags can be specified here in key=\"value\" format.\n[global_tags]\n\n#
    Configuration for telegraf agent\n[agent]\n    ## Default data collection interval
    for all inputs\n    interval = \"1m\"\n    ## Rounds collection interval to 'interval'\n
    \   ## ie, if interval=\"10s\" then always collect on :00, :10, :20, etc.\n    round_interval
    = true\n\n    ## Telegraf will send metrics to outputs in batches of at most\n
    \   ## metric_batch_size metrics.\n    ## This controls the size of writes that
    Telegraf sends to output plugins.\n    metric_batch_size = 1000\n\n    ## For
    failed writes, telegraf will cache metric_buffer_limit metrics for each\n    ##
    output, and will flush this buffer on a successful write. Oldest metrics\n    ##
    are dropped first when this buffer fills.\n    ## This buffer only fills when
    writes fail to output plugin(s).\n    metric_buffer_limit = 10000\n\n    ## Collection
    jitter is used to jitter the collection by a random amount.\n    ## Each plugin
    will sleep for a random time within jitter before collecting.\n    ## This can
    be used to avoid many plugins querying things like sysfs at the\n    ## same time,
    which can have a measurable effect on the system.\n    collection_jitter = \"0s\"\n\n
    \   ## Default flushing interval for all outputs. Maximum flush_interval will
    be\n    ## flush_interval + flush_jitter\n    flush_interval = \"10s\"\n    ##
    Jitter the flush interval by a random amount. This is primarily to avoid\n    ##
    large write spikes for users running a large number of telegraf instances.\n    ##
    ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s\n    flush_jitter
    = \"0s\"\n\n    ## By default or when set to \"0s\", precision will be set to
    the same\n    ## timestamp order as the collection interval, with the maximum
    being 1s.\n    ##   ie, when interval = \"10s\", precision will be \"1s\"\n    ##
    \      when interval = \"250ms\", precision will be \"1ms\"\n    ## Precision
    will NOT be used for service inputs. It is up to each individual\n    ## service
    input to set the timestamp at the appropriate precision.\n    ## Valid time units
    are \"ns\", \"us\" (or \"Âµs\"), \"ms\", \"s\".\n    precision = \"\"\n\n    ##
    Logging configuration:\n    ## Run telegraf with debug log messages.\n    debug
    = false\n    ## Run telegraf in quiet mode (error log messages only).\n    quiet
    = false\n    ## Specify the log file name. The empty string means to log to stderr.\n
    \   logfile = \"\"\n\n    ## Override default hostname, if empty use os.Hostname()\n
    \   #hostname = \"$NODE_NAME\"\n    ## If set to true, do no set the \"host\"
    tag in the telegraf agent.\n    omit_hostname = true\n\n\n\n\n###############################################################################\n#
    \                           OUTPUT PLUGINS                                   #\n###############################################################################\n\n#
    Configuration for sending metrics to InfluxDB\n[[outputs.influxdb]]\n    ## The
    full HTTP or UDP URL for your InfluxDB instance.\n    ##\n    ## Multiple URLs
    can be specified for a single cluster, only ONE of the\n    ## urls will be written
    to each interval.\n    # urls = [\"unix:///var/run/influxdb.sock\"]\n    # urls
    = [\"udp://127.0.0.1:8089\"]\n    # urls = [\"http://127.0.0.1:8086\"]\n    urls
    = [\"$INFLUXDB_URL\"]\n\n    ## The target database for metrics; will be created
    as needed.\n    database = \"$INFLUXDB_DB\"\n\n    ## If true, no CREATE DATABASE
    queries will be sent.  Set to true when using\n    ## Telegraf with a user without
    permissions to create databases or when the\n    ## database already exists.\n
    \   # skip_database_creation = false\n\n    ## Name of existing retention policy
    to write to.  Empty string writes to\n    ## the default retention policy.  Only
    takes effect when using HTTP.\n    # retention_policy = \"\"\n\n    ## Write consistency
    (clusters only), can be: \"any\", \"one\", \"quorum\", \"all\".\n    ## Only takes
    effect when using HTTP.\n    # write_consistency = \"any\"\n\n    ## Timeout for
    HTTP messages.\n    # timeout = \"5s\"\n\n    ## HTTP Basic Auth\n    username
    = \"$INFLUXDB_USER\"\n    password = \"$INFLUXDB_USER_PASSWORD\"\n\n    ## HTTP
    User-Agent\n    # user_agent = \"telegraf\"\n\n    ## UDP payload size is the
    maximum packet size to send.\n    # udp_payload = 512\n\n    ## Optional TLS Config
    for use on HTTP connections.\n    # tls_ca = \"/etc/telegraf/ca.pem\"\n    # tls_cert
    = \"/etc/telegraf/cert.pem\"\n    # tls_key = \"/etc/telegraf/key.pem\"\n    ##
    Use TLS but skip chain & host verification\n    # insecure_skip_verify = false\n\n
    \   ## HTTP Proxy override, if unset values the standard proxy environment\n    ##
    variables are consulted to determine which proxy, if any, should be used.\n    #
    http_proxy = \"http://corporate.proxy:3128\"\n\n    ## Additional HTTP headers\n
    \   # http_headers = {\"X-Special-Header\" = \"Special-Value\"}\n\n    ## HTTP
    Content-Encoding for write request body, can be set to \"gzip\" to\n    ## compress
    body or \"identity\" to apply no encoding.\n    # content_encoding = \"identity\"\n\n
    \   ## When true, Telegraf will output unsigned integers as unsigned values,\n
    \   ## i.e.: \"42u\".  You will need a version of InfluxDB supporting unsigned\n
    \   ## integer values.  Enabling this option will result in field type errors
    if\n    ## existing data has been written.\n    # influx_uint_support = false\n\n
    \   #[[outputs.file]]\n    ## Files to write to, \"stdout\" is a specially handled
    file.\n    #files = [\"stdout\", \"/tmp/metrics.out\"]\n\n    ## Use batch serialization
    format instead of line based delimiting.  The\n    ## batch format allows for
    the production of non line based output formats and\n    ## may more effiently
    encode and write metrics.\n    # use_batch_format = false\n\n    ## The file will
    be rotated after the time interval specified.  When set\n    ## to 0 no time based
    rotation is performed.\n    # rotation_interval = \"0h\"\n\n    ## The logfile
    will be rotated when it becomes larger than the specified\n    ## size.  When
    set to 0 no size based rotation is performed.\n    #rotation_max_size = \"10MB\"\n\n
    \   ## Maximum number of rotated archives to keep, any older logs are deleted.\n
    \   ## If set to -1, no archives are removed.\n    #rotation_max_archives = 5\n\n
    \   ## Data format to output.\n    ## Each data format has its own unique set
    of configuration options, read\n    ## more about them here:\n    ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md\n
    \   #data_format = \"influx\"\n\n###############################################################################\n#
    \                           INPUT PLUGINS                                    #\n###############################################################################\n\n#
    Read metrics from MQTT topic(s)\n[[inputs.mqtt_consumer]]\n    ## MQTT broker
    URLs to be used. The format should be scheme://host:port,\n    ## schema can be
    tcp, ssl, or ws.\n    servers = [\"tcp://192.168.1.202:1883\"]\n\n    ## Topics
    that will be subscribed to.\n    topics = [\n    \"telegraf/#\",\n    \"sensor/#\"\n
    \   ]\n\n    ## The message topic will be stored in a tag specified by this value.
    \ If set\n    ## to the empty string no topic tag will be created.\n    topic_tag
    = \"\"\n\n    ## QoS policy for messages\n    ##   0 = at most once\n    ##   1
    = at least once\n    ##   2 = exactly once\n    ##\n    ## When using a QoS of
    1 or 2, you should enable persistent_session to allow\n    ## resuming unacknowledged
    messages.\n    # qos = 0\n\n    ## Connection timeout for initial connection in
    seconds\n    # connection_timeout = \"30s\"\n\n    ## Maximum messages to read
    from the broker that have not been written by an\n    ## output.  For best throughput
    set based on the number of metrics within\n    ## each message and the size of
    the output's metric_batch_size.\n    ##\n    ## For example, if each message from
    the queue contains 10 metrics and the\n    ## output metric_batch_size is 1000,
    setting this to 100 will ensure that a\n    ## full batch is collected and the
    write is triggered immediately without\n    ## waiting until the next flush_interval.\n
    \   # max_undelivered_messages = 1000\n\n    ## Persistent session disables clearing
    of the client session on connection.\n    ## In order for this option to work
    you must also set client_id to identify\n    ## the client.  To receive messages
    that arrived while the client is offline,\n    ## also set the qos option to 1
    or 2 and don't forget to also set the QoS when\n    ## publishing.\n    # persistent_session
    = false\n\n    ## If unset, a random client ID will be generated.\n    # client_id
    = \"\"\n\n    #   ## Username and password to connect MQTT server.\n    # username
    = \"telegraf\"\n    # password = \"metricsmetricsmetricsmetrics\"\n\n    ## Optional
    TLS Config\n    # tls_ca = \"/etc/telegraf/ca.pem\"\n    # tls_cert = \"/etc/telegraf/cert.pem\"\n
    \   # tls_key = \"/etc/telegraf/key.pem\"\n    ## Use TLS but skip chain & host
    verification\n    # insecure_skip_verify = false\n\n    ## Data format to consume.\n
    \   ## Each data format has its own unique set of configuration options, read\n
    \   ## more about them here:\n    ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md\n
    \   data_format = \"influx\"\n\n[[inputs.kube_inventory]]\n    ## URL for the
    Kubernetes API\n    url = \"https://kubernetes.default.svc\"\n\n    ## Namespace
    to use. Set to \"\" to use all namespaces.\n    namespace = \"\"\n\n    ## Use
    bearer token for authorization. ('bearer_token' takes priority)\n    ## If both
    of these are empty, we'll use the default serviceaccount:\n    ## at: /run/secrets/kubernetes.io/serviceaccount/token\n
    \   bearer_token = \"/var/run/secrets/kubernetes.io/serviceaccount/token\"\n    ##
    OR\n    #bearer_token_string = \"\"\n\n    ## Set response_timeout (default 5
    seconds)\n    # response_timeout = \"5s\"\n\n    ## Optional Resources to exclude
    from gathering\n    ## Leave them with blank with try to gather everything available.\n
    \   ## Values can be - \"daemonsets\", deployments\", \"endpoints\", \"ingress\",
    \"nodes\",\n    ## \"persistentvolumes\", \"persistentvolumeclaims\", \"pods\",
    \"services\", \"statefulsets\"\n    #resource_exclude = [ \"deployments\", \"nodes\",
    \"statefulsets\" ]\n\n    ## Optional Resources to include when gathering\n    ##
    Overrides resource_exclude if both set.\n    resource_include = [\"pods\", \"nodes\"]
    \n    \n    ## Optional TLS Config\n    # tls_ca = \"/path/to/cafile\"\n    #
    tls_cert = \"/path/to/certfile\"\n    # tls_key = \"/path/to/keyfile\"\n    ##
    Use TLS but skip chain & host verification\n    insecure_skip_verify = true\n
    \   interval = \"1m\"\n\n## Network ##\n\n#[[inputs.exec]]\n#  commands = [\"sh
    /speedtest.sh\"]\n#  timeout = \"1m\"\n#  data_format = \"influx\"\n#  interval
    = \"60m\"\n\n[[inputs.ping]]\n\n    # WAN endpoints:\n\n    urls = [\"www.google.com\"]
    \n\n[[inputs.ping]]\n\n    # Network Devices:\n    #\n    # Network Infrastructure\n
    \   # ======================\n    # Main Router (VM)    - 192.168.1.1\n    # NAS
    \                - 192.168.1.2\n    # Managed Switch      - 192.168.1.3\n    #
    Xiamoi Router 4     - 192.168.1.254\n    #\n    # Entertainment\n    # =============\n
    \   # Shield TV           - 192.168.1.10\n    # Satelite TV Box     - 192.168.1.11\n
    \   # Lounge TV (LAN)     - 192.168.1.12\n    # Harry's TV (LAN)    - 192.168.1.13\n
    \   # Harry's TV (WiFi)   - 192.168.1.14\n    # Chloe's TV (WiFi)   - \n    #
    Harry's Nintendo    - \n    # Chloe's Nintendo    - \n    # PS5                 -
    192.168.1.18\n    #\n    # Laptops/Phones/Tablets\n    # =========\n    # Laptop
    P50          - 192.168.1.21\n    # Laptop P50 (VPN)    - 192.168.1.22\n    # Carolyn
    iPhone      - 192.168.1.23\n    # Carolyn iPad        - 192.168.1.24\n    # Samsung
    S21         - 192.168.1.25\n    # MacBook Pro         - 192.168.1.26\n    # Kid's
    iPad          -\n    # Garret SmartWatch   -\n    # Carolyn AppleWatch  - 192.168.1.28\n
    \   # Harry's Phone       - 192.168.1.29\n    #\n    # Servers/VMs\n    # ===========\n
    \   # RPi3 k8s-master     - 192.168.1.30\n    # RPi4 k8s-worker1    - 192.168.1.31\n
    \   # RPi4 k8s-worker2    - 192.168.1.32\n    # RPi4 k8s-worker3    - 192.168.1.33
    \n    # VM k8s-worker4      - 192.168.1.34 \n    # Lenovo G50-30       - 192.168.1.27
    -> 60\n    # Lenovo B50-30       - 192.168.1.61\n    # Lenovo W541         - 192.168.1.62
    \n    # Lenovo P50/Proxmox  - 192.168.1.70 \n    # \n    #\n    # Smart Devices\n
    \   # =============\n    # Chloe light         - 192.168.1.40\n    # Harry light
    \        - 192.168.1.41\n    # RPi Power Supply    - 192.168.1.42\n    # Kasa
    Energy Socket  - 192.168.1.43\n    # LG Tumble Dryer     - 192.168.1.44\n    #
    Bosch Oven          - 192.168.1.45\n    # Alexa (Lounge)      - 192.168.1.46\n
    \   # Alexa (Bedroom)     - 192.168.1.47\n    # Alexa (Harry)       - 192.168.1.48\n
    \   # Alexa (Chloe)       - 192.168.1.49\n    # Arlo BaseStation    - 192.168.1.50\n
    \   # HiveHub             - 192.168.1.51\n    # LightwaveRF Hub     - 192.168.1.52\n
    \   # Harmony Hub         - 192.168.1.53\n    # Google Nest Hub     - 192.168.1.54\n
    \   # Zigbee Bridge       - 192.168.1.55\n\n\n    urls = [\n    \"192.168.1.1\",
    \n    \"192.168.1.2\", \n    \"192.168.1.3\", \n    \"192.168.1.10\", \n    \"192.168.1.11\",
    \n    \"192.168.1.12\", \n    \"192.168.1.13\", \n    \"192.168.1.14\", \n    \"192.168.1.18\",
    \n    \"192.168.1.23\", \n    \"192.168.1.24\",\n    \"192.168.1.26\",\n    \"192.168.1.27\",
    \ \n    \"192.168.1.28\", \n    \"192.168.1.30\", \n    \"192.168.1.31\", \n    \"192.168.1.32\",
    \n    \"192.168.1.33\", \n    \"192.168.1.40\", \n    \"192.168.1.41\", \n    \"192.168.1.42\",
    \n    \"192.168.1.43\", \n    \"192.168.1.45\", \n    \"192.168.1.46\", \n    \"192.168.1.50\",
    \n    \"192.168.1.51\", \n    \"192.168.1.52\", \n    \"192.168.1.53\", \n    \"192.168.1.54\",
    \n    \"192.168.1.55\",\n    \"192.168.1.70\", \n    \"192.168.1.254\"] \n\n    [[processors.enum]]\n\n
    \   [[processors.enum.mapping]]\n        ## Name of the field to map\n        #field
    = \"status\"\n\n        ## Name of the tag to map\n        tag = \"url\"\n\n        ##
    Destination tag or field to be used for the mapped value.  By default the\n        ##
    source tag or field is used, overwriting the original value.\n        dest = \"host_map\"\n\n
    \       ## Default value to be used for all values not contained in the mapping\n
    \       ## table.  When unset and no match is found, the original field will remain
    \n        ## unmodified and the destination tag or field will not be created.\n
    \       default = \"unknown\"\n\n        ## Table of mappings\n        [processors.enum.mapping.value_mappings]\n
    \       \"192.168.1.1\" = \"Main Router\"\n        \"192.168.1.2\" = \"Linkstation
    NAS\"\n        \"192.168.1.3\" = \"Managed Switch\"\n        \"192.168.1.254\"
    = \"WiFi Router - Study\"\n        \"192.168.1.10\" = \"Shield TV\"\n        \"192.168.1.11\"
    = \"zGemma Sat Box\"\n        \"192.168.1.12\" = \"Lounge TV (LAN)\"\n        \"192.168.1.13\"
    = \"Harry's TV (LAN)\"\n        \"192.168.1.14\" = \"Harry's TV (WiFi)\"\n        \"192.168.1.16\"
    = \"Nintendo Switch (Harry)\"\n        \"192.168.1.17\" = \"Nintendo Switch (Chloe)\"\n
    \       \"192.168.1.18\" = \"Playstation 5\"\n        \"192.168.1.21\" = \"Chris's
    Laptop\"\n        \"192.168.1.22\" = \"Chris's Laptop (Bonded)\"\n        \"192.168.1.23\"
    = \"Carolyn's iPhone\"\n        \"192.168.1.24\" = \"Carolyn's iPad\"\n        \"192.168.1.25\"
    = \"Chris's phone\"\n        \"192.168.1.26\" = \"MacBook Pro\"\n        \"192.168.1.27\"
    = \"Lenovo-G50-30\"\n        \"192.168.1.28\" = \"Apple Watch\"         \n        \"192.168.1.30\"
    = \"Master node\"\n        \"192.168.1.31\" = \"Worker Node, k8s-worker1\"\n        \"192.168.1.32\"
    = \"Worker Node, k8s-worker2\"\n        \"192.168.1.33\" = \"Worker Node, k8s-worker3\"
    \   \n        \"192.168.1.34\" = \"Worker Node, k8s-worker4\"          \n        \"192.168.1.40\"
    = \"Chloe's Light\"\n        \"192.168.1.41\" = \"Harry's Light\"                                         \n
    \       \"192.168.1.42\" = \"RPi PSU\"\n        \"192.168.1.43\" = \"Smart Socket\"\n
    \       \"192.168.1.45\" = \"Bosch Oven\"\n        \"192.168.1.46\" = \"Amazon
    Alexa (Lounge)\"\n        \"192.168.1.47\" = \"Amazon Alexa (Bedroom)\"\n        \"192.168.1.48\"
    = \"Amazon Alexa (Harry)\"\n        \"192.168.1.49\" = \"Amazon Alexa (Chloe)\"\n
    \       \"192.168.1.50\" = \"Arlo Basestation\"\n        \"192.168.1.51\" = \"Hive
    Hub\"\n        \"192.168.1.52\" = \"LightwaveRF Hub\" \n        \"192.168.1.53\"
    = \"Harmony Hub\"\n        \"192.168.1.54\" = \"Google Nest Hub Max\"\n        \"192.168.1.55\"
    = \"Zigbee Bridge\"\n        \"192.168.1.60\" = \"Lenovo G50-30\"\n        \"192.168.1.61\"
    = \"Lenovo B50-30\"\n        \"192.168.1.70\" = \"Proxmox Host\"\n        \"www.google.com\"
    = \"www.google.com\"\n\n[[inputs.dns_query]]\n    servers = [\"8.8.8.8\"]\n    domains
    = [\"www.google.com\"]\n    record_type = \"A\"\n\n[[inputs.net_response]]\n    protocol
    = \"tcp\"\n    address = \"www.google.com:80\"\n    timeout = \"1s\"\n    read_timeout
    = \"1s\""
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: smart-home-collector-config
  namespace: iot
