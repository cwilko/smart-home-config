apiVersion: v1
data:
  telegraf.conf: "# Telegraf Configuration\n#\n# Telegraf is entirely plugin driven.
    All metrics are gathered from the\n# declared inputs, and sent to the declared
    outputs.\n#\n# Plugins must be declared in here to be active.\n# To deactivate
    a plugin, comment out the name and any variables.\n#\n# Use 'telegraf -config
    telegraf.conf -test' to see what metrics a config\n# file would generate.\n#\n#
    Environment variables can be used anywhere in this config file, simply prepend\n#
    them with $. For strings the variable must be within quotes (ie, \"$STR_VAR\"),\n#
    for numbers and booleans they should be plain (ie, $INT_VAR, $BOOL_VAR)\n\n\n#
    Global tags can be specified here in key=\"value\" format.\n[global_tags]\n\n#
    Configuration for telegraf agent\n[agent]\n    ## Default data collection interval
    for all inputs\n    interval = \"1m\"\n    ## Rounds collection interval to 'interval'\n
    \   ## ie, if interval=\"10s\" then always collect on :00, :10, :20, etc.\n    round_interval
    = true\n\n    ## Telegraf will send metrics to outputs in batches of at most\n
    \   ## metric_batch_size metrics.\n    ## This controls the size of writes that
    Telegraf sends to output plugins.\n    metric_batch_size = 1000\n\n    ## For
    failed writes, telegraf will cache metric_buffer_limit metrics for each\n    ##
    output, and will flush this buffer on a successful write. Oldest metrics\n    ##
    are dropped first when this buffer fills.\n    ## This buffer only fills when
    writes fail to output plugin(s).\n    metric_buffer_limit = 10000\n\n    ## Collection
    jitter is used to jitter the collection by a random amount.\n    ## Each plugin
    will sleep for a random time within jitter before collecting.\n    ## This can
    be used to avoid many plugins querying things like sysfs at the\n    ## same time,
    which can have a measurable effect on the system.\n    collection_jitter = \"0s\"\n\n
    \   ## Default flushing interval for all outputs. Maximum flush_interval will
    be\n    ## flush_interval + flush_jitter\n    flush_interval = \"10s\"\n    ##
    Jitter the flush interval by a random amount. This is primarily to avoid\n    ##
    large write spikes for users running a large number of telegraf instances.\n    ##
    ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s\n    flush_jitter
    = \"0s\"\n\n    ## By default or when set to \"0s\", precision will be set to
    the same\n    ## timestamp order as the collection interval, with the maximum
    being 1s.\n    ##   ie, when interval = \"10s\", precision will be \"1s\"\n    ##
    \      when interval = \"250ms\", precision will be \"1ms\"\n    ## Precision
    will NOT be used for service inputs. It is up to each individual\n    ## service
    input to set the timestamp at the appropriate precision.\n    ## Valid time units
    are \"ns\", \"us\" (or \"Âµs\"), \"ms\", \"s\".\n    precision = \"\"\n\n    ##
    Logging configuration:\n    ## Run telegraf with debug log messages.\n    debug
    = false\n    ## Run telegraf in quiet mode (error log messages only).\n    quiet
    = false\n    ## Specify the log file name. The empty string means to log to stderr.\n
    \   logfile = \"\"\n\n    ## Override default hostname, if empty use os.Hostname()\n
    \   hostname = \"$NODE_NAME\"\n    ## If set to true, do no set the \"host\" tag
    in the telegraf agent.\n    omit_hostname = false\n\n    ## Skip processors after
    aggregators (suppress v1.40.0 warning)\n    skip_processors_after_aggregators
    = false\n\n\n###############################################################################\n#
    \                           OUTPUT PLUGINS                                   #\n###############################################################################\n\n#
    Configuration for sending metrics to InfluxDB\n[[outputs.influxdb]]\n    ## The
    full HTTP or UDP URL for your InfluxDB instance.\n    ##\n    ## Multiple URLs
    can be specified for a single cluster, only ONE of the\n    ## urls will be written
    to each interval.\n    # urls = [\"unix:///var/run/influxdb.sock\"]\n    # urls
    = [\"udp://127.0.0.1:8089\"]\n    # urls = [\"http://127.0.0.1:8086\"]\n    urls
    = [\"$INFLUXDB_URL\"]\n\n    ## The target database for metrics; will be created
    as needed.\n    database = \"$INFLUXDB_DB\"\n\n    ## If true, no CREATE DATABASE
    queries will be sent.  Set to true when using\n    ## Telegraf with a user without
    permissions to create databases or when the\n    ## database already exists.\n
    \   # skip_database_creation = false\n\n    ## Name of existing retention policy
    to write to.  Empty string writes to\n    ## the default retention policy.  Only
    takes effect when using HTTP.\n    # retention_policy = \"\"\n\n    ## Write consistency
    (clusters only), can be: \"any\", \"one\", \"quorum\", \"all\".\n    ## Only takes
    effect when using HTTP.\n    # write_consistency = \"any\"\n\n    ## Timeout for
    HTTP messages.\n    # timeout = \"5s\"\n\n    ## HTTP Basic Auth\n    username
    = \"$INFLUXDB_USER\"\n    password = \"$INFLUXDB_USER_PASSWORD\"\n\n    ## HTTP
    User-Agent\n    # user_agent = \"telegraf\"\n\n    ## UDP payload size is the
    maximum packet size to send.\n    # udp_payload = 512\n\n    ## Optional TLS Config
    for use on HTTP connections.\n    # tls_ca = \"/etc/telegraf/ca.pem\"\n    # tls_cert
    = \"/etc/telegraf/cert.pem\"\n    # tls_key = \"/etc/telegraf/key.pem\"\n    ##
    Use TLS but skip chain & host verification\n    # insecure_skip_verify = false\n\n
    \   ## HTTP Proxy override, if unset values the standard proxy environment\n    ##
    variables are consulted to determine which proxy, if any, should be used.\n    #
    http_proxy = \"http://corporate.proxy:3128\"\n\n    ## Additional HTTP headers\n
    \   # http_headers = {\"X-Special-Header\" = \"Special-Value\"}\n\n    ## HTTP
    Content-Encoding for write request body, can be set to \"gzip\" to\n    ## compress
    body or \"identity\" to apply no encoding.\n    # content_encoding = \"identity\"\n\n
    \   ## When true, Telegraf will output unsigned integers as unsigned values,\n
    \   ## i.e.: \"42u\".  You will need a version of InfluxDB supporting unsigned\n
    \   ## integer values.  Enabling this option will result in field type errors
    if\n    ## existing data has been written.\n    # influx_uint_support = false\n\n
    \   #[[outputs.file]]\n    ## Files to write to, \"stdout\" is a specially handled
    file.\n    #files = [\"stdout\", \"/tmp/metrics.out\"]\n\n    ## Use batch serialization
    format instead of line based delimiting.  The\n    ## batch format allows for
    the production of non line based output formats and\n    ## may more effiently
    encode and write metrics.\n    # use_batch_format = false\n\n    ## The file will
    be rotated after the time interval specified.  When set\n    ## to 0 no time based
    rotation is performed.\n    # rotation_interval = \"0h\"\n\n    ## The logfile
    will be rotated when it becomes larger than the specified\n    ## size.  When
    set to 0 no size based rotation is performed.\n    # rotation_max_size = \"0MB\"\n\n
    \   ## Maximum number of rotated archives to keep, any older logs are deleted.\n
    \   ## If set to -1, no archives are removed.\n    # rotation_max_archives = 5\n\n
    \   ## Data format to output.\n    ## Each data format has its own unique set
    of configuration options, read\n    ## more about them here:\n    ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_OUTPUT.md\n
    \   #data_format = \"influx\"\n\n###############################################################################\n#
    \                           INPUT PLUGINS                                    #\n###############################################################################\n\n#
    Read metrics about cpu usage\n[[inputs.cpu]]\n    ## Whether to report per-cpu
    stats or not\n    percpu = true\n    ## Whether to report total system cpu stats
    or not\n    totalcpu = true\n    ## If true, collect raw CPU time metrics.\n    collect_cpu_time
    = false\n    ## If true, compute and report the sum of all non-idle CPU states.\n
    \   report_active = false\n\n\n# Read metrics about disk usage by mount point\n[[inputs.disk]]\n
    \   ## By default stats will be gathered for all mount points.\n    ## Set mount_points
    will restrict the stats to only the specified mount points.\n    # mount_points
    = [\"/\"]\n\n    ## Ignore mount points by filesystem type.\n    ignore_fs = [\"tmpfs\",
    \"devtmpfs\", \"devfs\", \"overlay\", \"aufs\", \"squashfs\", \"nfs\"]\n\n\n#
    Read metrics about disk IO by device\n[[inputs.diskio]]\n    ## By default, telegraf
    will gather stats for all devices including\n    ## disk partitions.\n    ## Setting
    devices will restrict the stats to the specified devices.\n    devices = [\"sda\",
    \"sdb\"]\n    ## Uncomment the following line if you need disk serial numbers.\n
    \   skip_serial_number = true\n    #\n    ## On systems which support it, device
    metadata can be added in the form of\n    ## tags.\n    ## Currently only Linux
    is supported via udev properties. You can view\n    ## available properties for
    a device by running:\n    ## 'udevadm info -q property -n /dev/sda'\n    # device_tags
    = [\"ID_FS_TYPE\", \"ID_FS_USAGE\"]\n    #\n    ## Using the same metadata source
    as device_tags, you can also customize the\n    ## name of the device via templates.\n
    \   ## The 'name_templates' parameter is a list of templates to try and apply
    to\n    ## the device. The template may contain variables in the form of '$PROPERTY'
    or\n    ## '${PROPERTY}'. The first template which does not contain any variables
    not\n    ## present for the device is used as the device name tag.\n    ## The
    typical use case is for LVM volumes, to get the VG/LV name instead of\n    ##
    the near-meaningless DM-0 name.\n    # name_templates = [\"$ID_FS_LABEL\",\"$DM_VG_NAME/$DM_LV_NAME\"]\n\n\n#
    Get kernel statistics from /proc/stat\n[[inputs.kernel]]\n    # no configuration\n\n\n#
    Read metrics about memory usage\n[[inputs.mem]]\n    # no configuration\n\n\n#
    Get the number of processes and group them by status\n[[inputs.processes]]\n    #
    no configuration\n\n\n# Read metrics about swap memory usage\n#[[inputs.swap]]\n
    \   # no configuration\n\n\n# Read metrics about system load & uptime\n[[inputs.system]]\n
    \   # no configuration\n\n# Collect TCP connections state and UDP socket counts\n[[inputs.netstat]]\n
    \   # no configuration\n\n# Gather metrics about network interfaces\n[[inputs.net]]\n
    \   ## By default, telegraf gathers stats from any up interface (excluding loopback)\n
    \   ## Setting interfaces will tell it to gather these explicit interfaces,\n
    \   ## regardless of status. When specifying an interface, glob-style\n    ##
    patterns are also supported.\n    ##\n    # interfaces = [\"eth*\", \"enp0s[0-1]\",
    \"lo\"]\n    ##\n    ## On linux systems telegraf also collects protocol stats.\n
    \   ## Setting ignore_protocol_stats to true will skip reporting of protocol metrics.\n
    \   ##\n    ignore_protocol_stats = true\n    ##\n\n# K3S does not user docker.
    Also the docker data is too low level - k8s collection is better.\n#[[inputs.docker]]\n#container_name_exclude
    = []\n#container_name_include = []\n#docker_label_exclude = []\n#docker_label_include
    = []\n#endpoint = \"unix:///var/run/docker.sock\"\n#gather_services = false\n#perdevice_include
    = [\"cpu\", \"network\", \"blkio\"]\n#timeout = \"10s\"\n\n\n#  # Raspberry Pi
    metrics\n#  [[inputs.exec]]\n#    commands = [\"vcgencmd measure_temp\"]\n#    name_override
    = \"gpu_temp\"\n#    data_format = \"grok\"\n#    grok_patterns = [\"%{NUMBER:value:float}\"]\n#\n#
    \ [[inputs.exec]]\n#    commands = [\"vcgencmd measure_temp pmic\"]\n#    name_override
    = \"pmic_temp\"\n#    data_format = \"grok\"\n#    grok_patterns = [\"%{NUMBER:value:float}\"]\n#\n#
    \ [[inputs.file]]\n#    files = [\"/sys/class/thermal/thermal_zone0/temp\"]\n#
    \   name_override = \"cpu_temp\"\n#    data_format = \"value\"\n#    data_type
    = \"integer\"  \n\n\n\n[[inputs.kubernetes]]\n#  ## URL for the Kubernetes API\n
    \   url = \"https://$NODE_IP_ADDRESS:10250\"\n#\n#  ## Namespace to use. Set to
    \"\" to use all namespaces.\n#  #namespace = \"\"\n#\n#  ## Use bearer token for
    authorization. ('bearer_token' takes priority)\n#  ## If both of these are empty,
    we'll use the default serviceaccount:\n#  ## at: /run/secrets/kubernetes.io/serviceaccount/token\n
    \   bearer_token = \"/var/run/secrets/kubernetes.io/serviceaccount/token\"\n#
    \ ## OR\n#  #bearer_token_string = \"\"\n#\n#  ## Set response_timeout (default
    5 seconds)\n#  # response_timeout = \"5s\"\n#\n#  ## Use TLS but skip chain &
    host verification\n    insecure_skip_verify = true\n\n    ## Only collect pod
    container metrics (exclude node, volume, system_container)\n    namepass = [\"kubernetes_pod_container\"]"
kind: ConfigMap
metadata:
  creationTimestamp: null
  name: telegraf-config-amd64
  namespace: iot
